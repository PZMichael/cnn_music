{
  "name": "CNN for music genres",
  "tagline": "A CNN for music genre classification and TSC in general",
  "body": "## CNN for music genres\r\nThis post presents a CNN for music genre classification. Over the last weeks, I got many positive reactions for my implementations of a [CNN](http://robromijnders.github.io/CNN_tsc/) and [LSTM](http://robromijnders.github.io/LSTM_tsc/) for time-series classification. With this post, we stretch the TSC domain to long signals. Music has a typical sample frequency of 44.1 kHz. For basic classification, you need at least 1 or 2 seconds of data. That implies a signal length of roughly 50.000 samples. This post implements a CNN with accuracies around 90%.\r\n\r\n## Downsampling architecture\r\nThe implementation downsamples in two stages. At first, _extract_music.m_ loads the data and applies a hard-coded downsample with factor 30. The resulting sample frequency is 1470Hz. The second downsampling occurs after the first conv-layer in *CNN_music_main.py*. An immediate downsampling with factor 90 would discard useful information. The first conv-layer in the CNN graph can extract useful information. The strided max-pooling condenses information with a factor 3. With a combined convolution and max-pooling, we allow for valuable information to be passed to the second conv-layer\r\n\r\n## Your own use\r\nThe goal is to show that even long sparse signals, like music, also allow for time-series classification. In this project, the MATLAB code in _extract_music.m_ extract chunks of signal from the music in a specific directory. You can cut down the project at every layer for your own use\r\n  * At the base level, you can import your own music.\r\n  * In the MATLAB code, there's many knobs to play with\r\n    * The chunk-length\r\n    * The down-sample factor\r\n    * For better performance, you can synchronize the chunks with the beat of the music\r\n  * You can discard the chunking all together and feed the music at original sample frequency to the CNN.\r\n  * At last, the CNN allows for many tuning, like the architecture, learning rate, number of neurons, regularization, dropout and so on.\r\n\r\n## Output\r\nWith the implementation set in the *.py* file, you can expect these outputs:\r\nThe evolution of the loss-function and the accuracies.\r\n![Loss_acc](https://github.com/RobRomijnders/cnn_music/blob/master/loss_acc_evol.png?raw=true)\r\nThe graph in TensorBoard\r\n![graph](https://github.com/RobRomijnders/cnn_music/blob/master/tensorboard.png?raw=true)\r\n\r\nAs always, I am curious to any comments and questions. Reach me at romijndersrob@gmail.com",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}